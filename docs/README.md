# Mushroom ETL Pipeline

A comprehensive ETL (Extract, Transform, Load) pipeline for mushroom classification data, demonstrating modern data engineering practices.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Virtual environment (venv)
- Git

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd mushroom_etl_project

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your configuration
```

### Running the Pipeline
```bash
# Run complete ETL pipeline
python scripts/run_etl.py

# Run specific stages
python scripts/run_extraction.py
python scripts/run_transformation.py
python scripts/run_loading.py
```

## ğŸ“Š Project Overview

This project demonstrates:
- **Data Extraction**: Multiple data sources (UCI dataset, files, APIs)
- **Data Transformation**: Cleaning, validation, feature engineering
- **Data Loading**: Database and file storage
- **ETL Orchestration**: Complete pipeline coordination
- **Testing**: Comprehensive test coverage
- **Monitoring**: Performance and quality tracking

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extraction    â”‚    â”‚ Transformation  â”‚    â”‚     Loading     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ UCI Dataset   â”‚â”€â”€â”€â–¶â”‚ â€¢ Data Cleaning â”‚â”€â”€â”€â–¶â”‚ â€¢ Database      â”‚
â”‚ â€¢ File Sources  â”‚    â”‚ â€¢ Feature Eng.  â”‚    â”‚ â€¢ File Storage  â”‚
â”‚ â€¢ API Sources   â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Quality Check â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
mushroom_etl_project/
â”œâ”€â”€ data/                    # Data storage
â”‚   â”œâ”€â”€ raw/                 # Raw data
â”‚   â”œâ”€â”€ processed/           # Processed data
â”‚   â””â”€â”€ models/              # ML models
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ extract/             # Data extraction
â”‚   â”œâ”€â”€ transform/           # Data transformation
â”‚   â”œâ”€â”€ load/                # Data loading
â”‚   â”œâ”€â”€ orchestration/       # ETL orchestration
â”‚   â””â”€â”€ utils/               # Utilities
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”œâ”€â”€ config/                  # Configuration files
â”œâ”€â”€ scripts/                 # Standalone scripts
â””â”€â”€ docs/                    # Documentation
```

## ğŸ§ª Testing

### Running Tests
```bash
# Run all tests
python scripts/run_tests.py

# Run specific test categories
python -m pytest tests/test_extract/ -v
python -m pytest tests/test_transform/ -v
python -m pytest tests/test_load/ -v
python -m pytest tests/test_integration/ -v

# Run with coverage
python -m pytest tests/ --cov=src --cov-report=html
```

### Test Coverage
- **Unit Tests**: Individual component testing
- **Integration Tests**: Component integration testing
- **End-to-End Tests**: Complete pipeline testing
- **Error Scenario Tests**: Failure case testing
- **Performance Tests**: Pipeline performance testing

## ğŸ“ˆ Monitoring

### Pipeline Health
```bash
# Check pipeline health
python scripts/check_pipeline_health.py

# View pipeline statistics
python scripts/view_pipeline_stats.py
```

### Logs
```bash
# View pipeline logs
tail -f logs/etl_pipeline.log

# View specific stage logs
grep "extraction" logs/etl_pipeline.log
```

## ğŸš€ Deployment

### Development
```bash
# Run in development mode
python scripts/run_complete_etl.py --mode development
```

### Production
```bash
# Run in production mode
python scripts/run_complete_etl.py --mode production
```

### Docker (Optional)
```bash
# Build Docker image
docker build -t mushroom-etl .

# Run with Docker
docker run -v $(pwd)/data:/app/data mushroom-etl
```

## ğŸ”§ Maintenance

### Data Management
```bash
# Clean old data
python scripts/cleanup_data.py

# Backup data
python scripts/backup_data.py
```

### Updates
```bash
# Update dependencies
pip install -r requirements.txt --upgrade

# Run migrations
python scripts/migrate.py
```

## ğŸ“š Documentation

- [API Reference](api_reference.md) - Complete API documentation for all classes and methods
- [Configuration Guide](configuration.md) - Comprehensive configuration options and examples
- [Deployment Guide](deployment.md) - Production deployment and monitoring
- [Troubleshooting](troubleshooting.md) - Common issues and solutions
- [Contributing](contributing.md) - How to contribute to the project

## ğŸ”§ Quick Reference

### Configuration Files
- `config/pipeline.yaml` - Pipeline configuration
- `config/database.yaml` - Database configuration
- `.env` - Environment variables (copy from `.env.example`)

### Key Scripts
- `scripts/run_complete_etl.py` - Run complete ETL pipeline
- `scripts/validate_setup.py` - Validate project setup
- `scripts/run_tests.py` - Run test suite
- `scripts/setup_project.py` - Automated project setup

### Data Flow
```
Raw Data â†’ Extraction â†’ Transformation â†’ Loading â†’ Processed Data
    â†“           â†“            â†“           â†“           â†“
  Files    DataFrames   Clean Data   Database    Analytics
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- UCI ML Repository for the mushroom dataset
- Python data science community
- Open source contributors
